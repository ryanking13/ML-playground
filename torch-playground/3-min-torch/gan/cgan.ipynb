{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matploitlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6c7f2c260250>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatploitlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matploitlib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import matploitlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 300\n",
    "BATCH_SIZE = 100\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.FashionMNIST(\n",
    "    \"./.data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=trainset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed =  nn.Embedding(10, 10)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(110, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, z, labels):\n",
    "        c = self.embed(labels)\n",
    "        x = torch.cat([z, c], 1)\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(10, 10)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784 + 10, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, labels):\n",
    "        c = self.embed(labels)\n",
    "        x = torch.cat([x, c], 1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator().to(DEVICE)\n",
    "G = Generator().to(DEVICE)\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=0.0002)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/300], d_loss: 0.3098, g_loss: 3.8268            D(x): 0.89, D(G(z)): 0.13\n",
      "Epoch [1/300], d_loss: 0.7070, g_loss: 2.9519            D(x): 0.81, D(G(z)): 0.24\n",
      "Epoch [2/300], d_loss: 0.5622, g_loss: 3.5931            D(x): 0.91, D(G(z)): 0.24\n",
      "Epoch [3/300], d_loss: 0.6224, g_loss: 2.6376            D(x): 0.88, D(G(z)): 0.23\n",
      "Epoch [4/300], d_loss: 0.6928, g_loss: 2.8056            D(x): 0.79, D(G(z)): 0.14\n",
      "Epoch [5/300], d_loss: 0.5979, g_loss: 2.5283            D(x): 0.85, D(G(z)): 0.24\n",
      "Epoch [6/300], d_loss: 0.8238, g_loss: 1.8892            D(x): 0.80, D(G(z)): 0.31\n",
      "Epoch [7/300], d_loss: 0.7647, g_loss: 1.7173            D(x): 0.72, D(G(z)): 0.28\n",
      "Epoch [8/300], d_loss: 0.6474, g_loss: 2.2031            D(x): 0.80, D(G(z)): 0.24\n",
      "Epoch [9/300], d_loss: 0.7032, g_loss: 2.0464            D(x): 0.74, D(G(z)): 0.20\n",
      "Epoch [10/300], d_loss: 1.1289, g_loss: 1.5758            D(x): 0.72, D(G(z)): 0.38\n",
      "Epoch [11/300], d_loss: 1.1821, g_loss: 1.5223            D(x): 0.74, D(G(z)): 0.41\n",
      "Epoch [12/300], d_loss: 0.5797, g_loss: 1.7537            D(x): 0.83, D(G(z)): 0.26\n",
      "Epoch [13/300], d_loss: 0.7300, g_loss: 1.6530            D(x): 0.74, D(G(z)): 0.27\n",
      "Epoch [14/300], d_loss: 0.8592, g_loss: 1.4285            D(x): 0.70, D(G(z)): 0.28\n",
      "Epoch [15/300], d_loss: 0.8696, g_loss: 1.4290            D(x): 0.69, D(G(z)): 0.31\n",
      "Epoch [16/300], d_loss: 1.0616, g_loss: 1.2700            D(x): 0.66, D(G(z)): 0.32\n",
      "Epoch [17/300], d_loss: 1.2028, g_loss: 1.3145            D(x): 0.60, D(G(z)): 0.38\n",
      "Epoch [18/300], d_loss: 1.0640, g_loss: 1.2402            D(x): 0.66, D(G(z)): 0.34\n",
      "Epoch [19/300], d_loss: 0.9762, g_loss: 1.4435            D(x): 0.68, D(G(z)): 0.34\n",
      "Epoch [20/300], d_loss: 0.9906, g_loss: 1.3792            D(x): 0.61, D(G(z)): 0.31\n",
      "Epoch [21/300], d_loss: 1.0608, g_loss: 1.0297            D(x): 0.67, D(G(z)): 0.42\n",
      "Epoch [22/300], d_loss: 0.7629, g_loss: 1.5095            D(x): 0.73, D(G(z)): 0.28\n",
      "Epoch [23/300], d_loss: 1.0733, g_loss: 1.1167            D(x): 0.63, D(G(z)): 0.37\n",
      "Epoch [24/300], d_loss: 1.1980, g_loss: 1.1194            D(x): 0.58, D(G(z)): 0.39\n",
      "Epoch [25/300], d_loss: 1.2365, g_loss: 1.5899            D(x): 0.56, D(G(z)): 0.30\n",
      "Epoch [26/300], d_loss: 0.9333, g_loss: 1.5396            D(x): 0.69, D(G(z)): 0.32\n",
      "Epoch [27/300], d_loss: 0.9712, g_loss: 1.4670            D(x): 0.70, D(G(z)): 0.34\n",
      "Epoch [28/300], d_loss: 0.8694, g_loss: 1.3503            D(x): 0.71, D(G(z)): 0.31\n",
      "Epoch [29/300], d_loss: 0.8712, g_loss: 1.3622            D(x): 0.71, D(G(z)): 0.30\n",
      "Epoch [30/300], d_loss: 1.0459, g_loss: 1.1269            D(x): 0.67, D(G(z)): 0.39\n",
      "Epoch [31/300], d_loss: 0.9325, g_loss: 1.2729            D(x): 0.69, D(G(z)): 0.34\n",
      "Epoch [32/300], d_loss: 0.9848, g_loss: 1.2201            D(x): 0.70, D(G(z)): 0.39\n",
      "Epoch [33/300], d_loss: 1.0918, g_loss: 1.2122            D(x): 0.64, D(G(z)): 0.37\n",
      "Epoch [34/300], d_loss: 1.0187, g_loss: 1.2435            D(x): 0.71, D(G(z)): 0.40\n",
      "Epoch [35/300], d_loss: 1.2621, g_loss: 1.3687            D(x): 0.59, D(G(z)): 0.34\n",
      "Epoch [36/300], d_loss: 1.0951, g_loss: 1.1138            D(x): 0.67, D(G(z)): 0.39\n",
      "Epoch [37/300], d_loss: 1.1389, g_loss: 1.0043            D(x): 0.58, D(G(z)): 0.39\n",
      "Epoch [38/300], d_loss: 1.1265, g_loss: 1.2563            D(x): 0.61, D(G(z)): 0.35\n",
      "Epoch [39/300], d_loss: 1.0717, g_loss: 1.2487            D(x): 0.60, D(G(z)): 0.33\n",
      "Epoch [40/300], d_loss: 1.0674, g_loss: 1.1598            D(x): 0.65, D(G(z)): 0.39\n",
      "Epoch [41/300], d_loss: 1.2586, g_loss: 1.1012            D(x): 0.56, D(G(z)): 0.38\n",
      "Epoch [42/300], d_loss: 1.0241, g_loss: 1.2050            D(x): 0.68, D(G(z)): 0.39\n",
      "Epoch [43/300], d_loss: 0.9870, g_loss: 1.1932            D(x): 0.65, D(G(z)): 0.34\n",
      "Epoch [44/300], d_loss: 1.0221, g_loss: 1.0972            D(x): 0.67, D(G(z)): 0.39\n",
      "Epoch [45/300], d_loss: 1.2125, g_loss: 1.0534            D(x): 0.60, D(G(z)): 0.41\n",
      "Epoch [46/300], d_loss: 1.1822, g_loss: 1.0173            D(x): 0.62, D(G(z)): 0.43\n",
      "Epoch [47/300], d_loss: 1.0728, g_loss: 1.1262            D(x): 0.63, D(G(z)): 0.37\n",
      "Epoch [48/300], d_loss: 1.1195, g_loss: 1.2452            D(x): 0.62, D(G(z)): 0.33\n",
      "Epoch [49/300], d_loss: 1.2330, g_loss: 1.1449            D(x): 0.57, D(G(z)): 0.39\n",
      "Epoch [50/300], d_loss: 1.1030, g_loss: 1.2518            D(x): 0.61, D(G(z)): 0.33\n",
      "Epoch [51/300], d_loss: 1.2142, g_loss: 1.0532            D(x): 0.64, D(G(z)): 0.44\n",
      "Epoch [52/300], d_loss: 1.0529, g_loss: 0.9938            D(x): 0.65, D(G(z)): 0.41\n",
      "Epoch [53/300], d_loss: 1.1320, g_loss: 1.0684            D(x): 0.60, D(G(z)): 0.41\n",
      "Epoch [54/300], d_loss: 1.1016, g_loss: 1.1003            D(x): 0.62, D(G(z)): 0.37\n",
      "Epoch [55/300], d_loss: 1.2818, g_loss: 0.9225            D(x): 0.56, D(G(z)): 0.44\n",
      "Epoch [56/300], d_loss: 1.1250, g_loss: 1.1713            D(x): 0.59, D(G(z)): 0.35\n",
      "Epoch [57/300], d_loss: 1.1385, g_loss: 1.2916            D(x): 0.59, D(G(z)): 0.35\n",
      "Epoch [58/300], d_loss: 1.2473, g_loss: 1.2229            D(x): 0.68, D(G(z)): 0.41\n",
      "Epoch [59/300], d_loss: 1.1091, g_loss: 0.9402            D(x): 0.63, D(G(z)): 0.41\n",
      "Epoch [60/300], d_loss: 1.1151, g_loss: 0.9537            D(x): 0.65, D(G(z)): 0.43\n",
      "Epoch [61/300], d_loss: 1.1741, g_loss: 1.0694            D(x): 0.66, D(G(z)): 0.43\n",
      "Epoch [62/300], d_loss: 1.2443, g_loss: 0.9982            D(x): 0.56, D(G(z)): 0.41\n",
      "Epoch [63/300], d_loss: 1.2842, g_loss: 1.0788            D(x): 0.57, D(G(z)): 0.40\n",
      "Epoch [64/300], d_loss: 1.1247, g_loss: 0.9906            D(x): 0.58, D(G(z)): 0.39\n",
      "Epoch [65/300], d_loss: 1.1849, g_loss: 0.8174            D(x): 0.60, D(G(z)): 0.45\n",
      "Epoch [66/300], d_loss: 1.2132, g_loss: 0.9976            D(x): 0.55, D(G(z)): 0.40\n",
      "Epoch [67/300], d_loss: 1.3092, g_loss: 1.0607            D(x): 0.58, D(G(z)): 0.42\n",
      "Epoch [68/300], d_loss: 1.1095, g_loss: 1.2613            D(x): 0.62, D(G(z)): 0.37\n",
      "Epoch [69/300], d_loss: 1.1861, g_loss: 1.1433            D(x): 0.56, D(G(z)): 0.37\n",
      "Epoch [70/300], d_loss: 1.1392, g_loss: 0.9706            D(x): 0.64, D(G(z)): 0.44\n",
      "Epoch [71/300], d_loss: 1.1475, g_loss: 1.3249            D(x): 0.63, D(G(z)): 0.37\n",
      "Epoch [72/300], d_loss: 0.9966, g_loss: 1.1407            D(x): 0.64, D(G(z)): 0.35\n",
      "Epoch [73/300], d_loss: 1.0664, g_loss: 1.1560            D(x): 0.62, D(G(z)): 0.37\n",
      "Epoch [74/300], d_loss: 1.2166, g_loss: 1.0991            D(x): 0.58, D(G(z)): 0.39\n",
      "Epoch [75/300], d_loss: 1.2634, g_loss: 1.0310            D(x): 0.56, D(G(z)): 0.42\n",
      "Epoch [76/300], d_loss: 1.2413, g_loss: 0.9787            D(x): 0.56, D(G(z)): 0.40\n",
      "Epoch [77/300], d_loss: 1.2701, g_loss: 1.1161            D(x): 0.55, D(G(z)): 0.37\n",
      "Epoch [78/300], d_loss: 1.2104, g_loss: 1.0955            D(x): 0.62, D(G(z)): 0.40\n",
      "Epoch [79/300], d_loss: 1.0316, g_loss: 1.3136            D(x): 0.66, D(G(z)): 0.37\n",
      "Epoch [80/300], d_loss: 1.1902, g_loss: 1.1285            D(x): 0.62, D(G(z)): 0.40\n",
      "Epoch [81/300], d_loss: 1.0362, g_loss: 1.4862            D(x): 0.62, D(G(z)): 0.29\n",
      "Epoch [82/300], d_loss: 1.0777, g_loss: 1.0191            D(x): 0.60, D(G(z)): 0.38\n",
      "Epoch [83/300], d_loss: 1.2846, g_loss: 1.1552            D(x): 0.57, D(G(z)): 0.37\n",
      "Epoch [84/300], d_loss: 1.0725, g_loss: 0.9466            D(x): 0.66, D(G(z)): 0.42\n",
      "Epoch [85/300], d_loss: 1.1466, g_loss: 1.0511            D(x): 0.64, D(G(z)): 0.42\n",
      "Epoch [86/300], d_loss: 1.3915, g_loss: 1.1597            D(x): 0.46, D(G(z)): 0.35\n",
      "Epoch [87/300], d_loss: 1.2334, g_loss: 0.9028            D(x): 0.55, D(G(z)): 0.43\n",
      "Epoch [88/300], d_loss: 1.3770, g_loss: 1.0511            D(x): 0.50, D(G(z)): 0.40\n",
      "Epoch [89/300], d_loss: 1.2479, g_loss: 0.9419            D(x): 0.60, D(G(z)): 0.45\n",
      "Epoch [90/300], d_loss: 1.0748, g_loss: 1.0839            D(x): 0.58, D(G(z)): 0.34\n",
      "Epoch [91/300], d_loss: 1.2635, g_loss: 1.0511            D(x): 0.62, D(G(z)): 0.43\n",
      "Epoch [92/300], d_loss: 1.1507, g_loss: 1.2222            D(x): 0.59, D(G(z)): 0.34\n",
      "Epoch [93/300], d_loss: 1.1646, g_loss: 0.9776            D(x): 0.58, D(G(z)): 0.41\n",
      "Epoch [94/300], d_loss: 1.2972, g_loss: 0.9260            D(x): 0.56, D(G(z)): 0.42\n",
      "Epoch [95/300], d_loss: 1.3057, g_loss: 0.8653            D(x): 0.55, D(G(z)): 0.44\n",
      "Epoch [96/300], d_loss: 1.4162, g_loss: 0.8433            D(x): 0.55, D(G(z)): 0.48\n",
      "Epoch [97/300], d_loss: 1.1453, g_loss: 1.1890            D(x): 0.62, D(G(z)): 0.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/300], d_loss: 1.0603, g_loss: 1.1251            D(x): 0.65, D(G(z)): 0.39\n",
      "Epoch [99/300], d_loss: 1.1074, g_loss: 1.0353            D(x): 0.62, D(G(z)): 0.38\n",
      "Epoch [100/300], d_loss: 1.1944, g_loss: 0.9210            D(x): 0.57, D(G(z)): 0.42\n",
      "Epoch [101/300], d_loss: 1.0131, g_loss: 1.1608            D(x): 0.68, D(G(z)): 0.39\n",
      "Epoch [102/300], d_loss: 1.1689, g_loss: 1.0504            D(x): 0.56, D(G(z)): 0.35\n",
      "Epoch [103/300], d_loss: 1.2978, g_loss: 0.9357            D(x): 0.55, D(G(z)): 0.43\n",
      "Epoch [104/300], d_loss: 1.1532, g_loss: 0.9188            D(x): 0.59, D(G(z)): 0.42\n",
      "Epoch [105/300], d_loss: 1.1794, g_loss: 1.0404            D(x): 0.59, D(G(z)): 0.40\n",
      "Epoch [106/300], d_loss: 1.1261, g_loss: 1.0179            D(x): 0.59, D(G(z)): 0.39\n",
      "Epoch [107/300], d_loss: 1.2410, g_loss: 0.9444            D(x): 0.58, D(G(z)): 0.43\n",
      "Epoch [108/300], d_loss: 1.2071, g_loss: 1.0792            D(x): 0.58, D(G(z)): 0.38\n",
      "Epoch [109/300], d_loss: 1.2559, g_loss: 1.0242            D(x): 0.55, D(G(z)): 0.41\n",
      "Epoch [110/300], d_loss: 1.2320, g_loss: 1.0562            D(x): 0.58, D(G(z)): 0.42\n",
      "Epoch [111/300], d_loss: 1.0972, g_loss: 1.2069            D(x): 0.65, D(G(z)): 0.40\n",
      "Epoch [112/300], d_loss: 1.0301, g_loss: 1.2096            D(x): 0.64, D(G(z)): 0.36\n",
      "Epoch [113/300], d_loss: 1.1539, g_loss: 1.1398            D(x): 0.62, D(G(z)): 0.37\n",
      "Epoch [114/300], d_loss: 1.1659, g_loss: 0.9706            D(x): 0.62, D(G(z)): 0.43\n",
      "Epoch [115/300], d_loss: 0.9997, g_loss: 1.2081            D(x): 0.64, D(G(z)): 0.36\n",
      "Epoch [116/300], d_loss: 1.1949, g_loss: 0.9779            D(x): 0.57, D(G(z)): 0.39\n",
      "Epoch [117/300], d_loss: 1.1484, g_loss: 0.9581            D(x): 0.60, D(G(z)): 0.42\n",
      "Epoch [118/300], d_loss: 1.1553, g_loss: 1.1545            D(x): 0.63, D(G(z)): 0.41\n",
      "Epoch [119/300], d_loss: 1.0851, g_loss: 1.0509            D(x): 0.59, D(G(z)): 0.39\n",
      "Epoch [120/300], d_loss: 1.1556, g_loss: 1.0264            D(x): 0.63, D(G(z)): 0.41\n",
      "Epoch [121/300], d_loss: 1.0894, g_loss: 1.0837            D(x): 0.62, D(G(z)): 0.36\n",
      "Epoch [122/300], d_loss: 1.0740, g_loss: 0.9881            D(x): 0.67, D(G(z)): 0.42\n",
      "Epoch [123/300], d_loss: 1.2514, g_loss: 1.0215            D(x): 0.62, D(G(z)): 0.42\n",
      "Epoch [124/300], d_loss: 1.1104, g_loss: 1.0872            D(x): 0.60, D(G(z)): 0.37\n",
      "Epoch [125/300], d_loss: 1.1519, g_loss: 1.0228            D(x): 0.59, D(G(z)): 0.39\n",
      "Epoch [126/300], d_loss: 1.2508, g_loss: 0.8486            D(x): 0.57, D(G(z)): 0.44\n",
      "Epoch [127/300], d_loss: 1.2383, g_loss: 1.0342            D(x): 0.58, D(G(z)): 0.42\n",
      "Epoch [128/300], d_loss: 1.2616, g_loss: 0.9282            D(x): 0.59, D(G(z)): 0.46\n",
      "Epoch [129/300], d_loss: 1.3156, g_loss: 0.8484            D(x): 0.60, D(G(z)): 0.45\n",
      "Epoch [130/300], d_loss: 1.3314, g_loss: 0.9137            D(x): 0.51, D(G(z)): 0.42\n",
      "Epoch [131/300], d_loss: 1.1618, g_loss: 0.9550            D(x): 0.60, D(G(z)): 0.43\n",
      "Epoch [132/300], d_loss: 1.1600, g_loss: 1.0512            D(x): 0.63, D(G(z)): 0.41\n",
      "Epoch [133/300], d_loss: 1.1232, g_loss: 0.9499            D(x): 0.60, D(G(z)): 0.39\n",
      "Epoch [134/300], d_loss: 1.3364, g_loss: 0.9216            D(x): 0.55, D(G(z)): 0.47\n",
      "Epoch [135/300], d_loss: 1.1867, g_loss: 0.8544            D(x): 0.58, D(G(z)): 0.43\n",
      "Epoch [136/300], d_loss: 1.2757, g_loss: 1.1264            D(x): 0.60, D(G(z)): 0.41\n",
      "Epoch [137/300], d_loss: 1.2409, g_loss: 1.0929            D(x): 0.58, D(G(z)): 0.40\n",
      "Epoch [138/300], d_loss: 1.1929, g_loss: 1.0588            D(x): 0.57, D(G(z)): 0.39\n",
      "Epoch [139/300], d_loss: 1.2684, g_loss: 0.8683            D(x): 0.55, D(G(z)): 0.44\n",
      "Epoch [140/300], d_loss: 1.2825, g_loss: 0.9348            D(x): 0.54, D(G(z)): 0.43\n",
      "Epoch [141/300], d_loss: 1.1338, g_loss: 1.1569            D(x): 0.57, D(G(z)): 0.37\n",
      "Epoch [142/300], d_loss: 1.3978, g_loss: 0.9117            D(x): 0.51, D(G(z)): 0.44\n",
      "Epoch [143/300], d_loss: 1.3083, g_loss: 1.0860            D(x): 0.54, D(G(z)): 0.38\n",
      "Epoch [144/300], d_loss: 1.1621, g_loss: 1.1702            D(x): 0.59, D(G(z)): 0.37\n",
      "Epoch [145/300], d_loss: 1.0656, g_loss: 0.9705            D(x): 0.67, D(G(z)): 0.42\n",
      "Epoch [146/300], d_loss: 1.2700, g_loss: 0.9522            D(x): 0.51, D(G(z)): 0.40\n",
      "Epoch [147/300], d_loss: 1.1509, g_loss: 0.8293            D(x): 0.60, D(G(z)): 0.44\n",
      "Epoch [148/300], d_loss: 1.3531, g_loss: 0.8357            D(x): 0.54, D(G(z)): 0.46\n",
      "Epoch [149/300], d_loss: 1.2087, g_loss: 0.9499            D(x): 0.61, D(G(z)): 0.42\n",
      "Epoch [150/300], d_loss: 1.2323, g_loss: 0.9611            D(x): 0.56, D(G(z)): 0.44\n",
      "Epoch [151/300], d_loss: 1.3079, g_loss: 1.1347            D(x): 0.54, D(G(z)): 0.38\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(BATCH_SIZE, -1).to(DEVICE)\n",
    "        real_labels = torch.ones(BATCH_SIZE, 1).to(DEVICE)\n",
    "        fake_labels = torch.zeros(BATCH_SIZE, 1).to(DEVICE)\n",
    "        \n",
    "        labels = labels.to(DEVICE)\n",
    "        outputs = D(images, labels)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "        \n",
    "        z = torch.randn(BATCH_SIZE, 100).to(DEVICE)\n",
    "        g_label = torch.randint(0, 10, (BATCH_SIZE,)).to(DEVICE)\n",
    "        fake_images = G(z, g_label)\n",
    "        \n",
    "        outputs = D(fake_images, g_label)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        \n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        fake_images = G(z, g_label)\n",
    "        outputs = D(fake_images, g_label)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch}/{EPOCHS}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}\\\n",
    "            D(x): {real_score.mean().item():.2f}, D(G(z)): {fake_score.mean().item():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_number = 9\n",
    "z = torch.randn(1, 100).to(DEVICE)\n",
    "g_label = torch.full((1,), item_number, dtype=torch.long).to(DEVICE)\n",
    "sample_images = G(z, g_label)\n",
    "\n",
    "sample_images_img = np.reshape(sample_images.data.cpu().numpy()\n",
    "                               [0],(28, 28))\n",
    "plt.imshow(sample_images_img, cmap = 'gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
