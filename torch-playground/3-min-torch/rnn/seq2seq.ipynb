{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello ->  [104, 101, 108, 108, 111]\n",
      "hola  ->  [104, 111, 108, 97]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 256\n",
    "x_ = list(map(ord, \"hello\"))\n",
    "y_ = list(map(ord, \"hola\"))\n",
    "print(\"hello -> \", x_)\n",
    "print(\"hola  -> \", y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.LongTensor(x_)\n",
    "y = torch.LongTensor(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.n_layers = 1\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.encoder = nn.GRU(hidden_size, hidden_size)\n",
    "        self.decoder = nn.GRU(hidden_size, hidden_size)\n",
    "        self.project = nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        initial_state = self._init_state()\n",
    "        embedding = self.embedding(inputs).unsqueeze(1)\n",
    "        \n",
    "        encoder_output = encoder_state = self.encoder(embedding, initial_state)\n",
    "        decoder_state = encoder_state\n",
    "        decoder_input = torch.LongTensor([0])\n",
    "        \n",
    "        outputs = []\n",
    "        \n",
    "        for i in range(targets.size()[0]):\n",
    "            decoder_input = self.embedding(decoder_input).unsqueeze(1)\n",
    "            decoder_output, decoder_state = self.decoder(decoder_input, decoder_state)\n",
    "            projection = self.project(decoder_output)\n",
    "            outputs.append(projection)\n",
    "            \n",
    "            decoder_input = torch.LongTensor([targets[i]])\n",
    "\n",
    "        outputs = torch.stack(outputs).squeeze()\n",
    "        return outputs\n",
    "    \n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return weight.new(self.n_layers, batch_size, self.hidden_size).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-156f509e490b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mlog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseq2seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acebr\\desktop\\keras-playground\\torch-playground\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-cad6e496599d>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, targets)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mdecoder_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mprojection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprojection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acebr\\desktop\\keras-playground\\torch-playground\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acebr\\desktop\\keras-playground\\torch-playground\\venv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    722\u001b[0m             \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 724\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    725\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[1;32mc:\\users\\acebr\\desktop\\keras-playground\\torch-playground\\venv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\acebr\\desktop\\keras-playground\\torch-playground\\venv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[1;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Expected hidden size {}, got {}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;31m# type: (Tensor, Tuple[int, int, int], str) -> None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "seq2seq = Seq2Seq(vocab_size, 16)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(seq2seq.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "log = []\n",
    "for i in range(1000):\n",
    "    prediction = seq2seq(x, y)\n",
    "    loss = criterion(prediction, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_val = loss.data\n",
    "    log.append(loss_val)\n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n 반복:%d 오차: %s\" % (i, loss_val.item()))\n",
    "        _, top1 = prediction.data.topk(1, 1)\n",
    "        print([chr(c) for c in top1.squeeze().numpy().tolist()])\n",
    "\n",
    "\n",
    "plt.plot(log)\n",
    "plt.ylabel('cross entropy loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello ->  [104, 101, 108, 108, 111]\n",
      "hola  ->  [104, 111, 108, 97]\n",
      "\n",
      " 반복:0 오차: 5.510807991027832\n",
      "['\\x84', 'ä', 'ä', 'ä']\n",
      "\n",
      " 반복:100 오차: 1.977390170097351\n",
      "['o', 'o', 'o', 'o']\n",
      "\n",
      " 반복:200 오차: 0.8158316612243652\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:300 오차: 0.3874143362045288\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:400 오차: 0.20920610427856445\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:500 오차: 0.1351446807384491\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:600 오차: 0.09580101817846298\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:700 오차: 0.07147827744483948\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:800 오차: 0.055182408541440964\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:900 오차: 0.04383453354239464\n",
      "['h', 'o', 'l', 'a']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "vocab_size = 256  # 총 아스키 코드 개수\n",
    "x_ = list(map(ord, \"hello\"))  # 아스키 코드 리스트로 변환\n",
    "y_ = list(map(ord, \"hola\"))   # 아스키 코드 리스트로 변환\n",
    "print(\"hello -> \", x_)\n",
    "print(\"hola  -> \", y_)\n",
    "\n",
    "\n",
    "x = torch.LongTensor(x_)\n",
    "y = torch.LongTensor(y_)\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.n_layers = 1\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.encoder = nn.GRU(hidden_size, hidden_size)\n",
    "        self.decoder = nn.GRU(hidden_size, hidden_size)\n",
    "        self.project = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # 인코더에 들어갈 입력\n",
    "        initial_state = self._init_state()\n",
    "        embedding = self.embedding(inputs).unsqueeze(1)\n",
    "        # embedding = [seq_len, batch_size, embedding_size]\n",
    "        \n",
    "        # 인코더 (Encoder)\n",
    "        encoder_output, encoder_state = self.encoder(embedding, initial_state)\n",
    "        # encoder_output = [seq_len, batch_size, hidden_size]\n",
    "        # encoder_state  = [n_layers, seq_len, hidden_size]\n",
    "\n",
    "        # 디코더에 들어갈 입력\n",
    "        decoder_state = encoder_state\n",
    "        decoder_input = torch.LongTensor([0])\n",
    "        \n",
    "        # 디코더 (Decoder)\n",
    "        outputs = []\n",
    "        \n",
    "        for i in range(targets.size()[0]):\n",
    "            decoder_input = self.embedding(decoder_input).unsqueeze(1)\n",
    "            decoder_output, decoder_state = self.decoder(decoder_input, decoder_state)\n",
    "            projection = self.project(decoder_output)\n",
    "            outputs.append(projection)\n",
    "            \n",
    "            #티처 포싱(Teacher Forcing) 사용\n",
    "            decoder_input = torch.LongTensor([targets[i]])\n",
    "\n",
    "        outputs = torch.stack(outputs).squeeze()\n",
    "        return outputs\n",
    "    \n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return weight.new(self.n_layers, batch_size, self.hidden_size).zero_()\n",
    "\n",
    "\n",
    "seq2seq = Seq2Seq(vocab_size, 16)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(seq2seq.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "log = []\n",
    "for i in range(1000):\n",
    "    prediction = seq2seq(x, y)\n",
    "    loss = criterion(prediction, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_val = loss.data\n",
    "    log.append(loss_val)\n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n 반복:%d 오차: %s\" % (i, loss_val.item()))\n",
    "        _, top1 = prediction.data.topk(1, 1)\n",
    "        print([chr(c) for c in top1.squeeze().numpy().tolist()])\n",
    "\n",
    "\n",
    "plt.plot(log)\n",
    "plt.ylabel('cross entropy loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
